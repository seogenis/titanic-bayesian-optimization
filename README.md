
# Titanic Challenge Hyperparameter Tuning

This project aims to optimize machine learning models to predict Titanic survivors using hyperparameter tuning techniques. The notebook focuses on selecting the best model through rigorous tuning and evaluation.

## Summary

The goal of this project is to create an accurate model that predicts Titanic survivors based on their attributes. The project includes entering the results into the [Titanic Kaggle competition](https://www.kaggle.com/competitions/titanic/overview). A unique aspect of this project is the use of nested hyper-tuners, such as Grid Search and Bayesian Optimizer parameters, to refine model hyperparameters.

## Key Components

- **Data Cleaning:** Handling missing values and preparing the dataset for modeling.
- **Feature Engineering:** Creating new features to enhance model performance.
- **Model Selection:** Using various classifiers, including MLP, Logistic Regression, Random Forest, and SVM, to find the best fit.
- **Hyperparameter Tuning:** Implementing Grid Search and Bayesian Optimization to fine-tune model parameters for optimal performance.
- **Evaluation:** Comparing models using metrics like accuracy, precision, recall, and F1-score to ensure robust predictions.
