{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "i2Hm76uvyP3O",
        "hhtKwQhCyLuH",
        "vT1AzFmjgXWO",
        "cx3RWfspNcRx"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "The goal of this project is to create the best MLP model that accurately predicts Titanic survivors based on their attributes, then enter the results into the Titanic Kaggle competition https://www.kaggle.com/competitions/titanic/overview\n",
        "\n",
        "A unique feature of this project is the usage of nested hyper-tuners(Grid Search of Bayesian Optimizer parameters) to optimize model hyperparameters"
      ],
      "metadata": {
        "id": "i-rkmy2m1Skv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing"
      ],
      "metadata": {
        "id": "i2Hm76uvyP3O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lmKD-sAu2u-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b0e1bf3-2c51-4c27-bbb9-319b86ef2e0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/176.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U keras-tuner\n",
        "\n",
        "from random import randint\n",
        "import seaborn as sn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from scipy import stats\n",
        "import keras_tuner as kt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import linear_model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras import initializers\n",
        "seed = 1234\n",
        "tf.random.set_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def plot_acc(history, ax = None, xlabel = 'Epoch #'):\n",
        "    if hasattr(history, 'history_'):\n",
        "      history = history.history_\n",
        "    else:\n",
        "      history = history.history\n",
        "    history.update({'epoch':list(range(len(history['val_accuracy'])))})\n",
        "    history = pd.DataFrame.from_dict(history)\n",
        "\n",
        "    best_epoch = history.sort_values(by = 'val_accuracy', ascending = False).iloc[0]['epoch']\n",
        "\n",
        "    if not ax:\n",
        "      f, ax = plt.subplots(1,1)\n",
        "    sn.lineplot(x = 'epoch', y = 'val_accuracy', data = history, label = 'Validation', ax = ax)\n",
        "    sn.lineplot(x = 'epoch', y = 'accuracy', data = history, label = 'Training', ax = ax)\n",
        "    ax.axhline(0.5, linestyle = '--',color='red', label = 'Chance')\n",
        "    ax.axvline(x = best_epoch, linestyle = '--', color = 'green', label = 'Best Epoch')  \n",
        "    ax.legend(loc = 7)    \n",
        "    ax.set_ylim([0.4, 1])\n",
        "\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel('Accuracy (Fraction)')\n",
        "    \n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "EO3NN9bGw0at"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning"
      ],
      "metadata": {
        "id": "hhtKwQhCyLuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('test.csv')\n",
        "#test_df.isna().sum()\n",
        "test_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CqNpUc345b4",
        "outputId": "3c68efbd-8b80-45d5-8fbf-ec40dc092e92"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 418 entries, 0 to 417\n",
            "Data columns (total 11 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  418 non-null    int64  \n",
            " 1   Pclass       418 non-null    int64  \n",
            " 2   Name         418 non-null    object \n",
            " 3   Sex          418 non-null    object \n",
            " 4   Age          332 non-null    float64\n",
            " 5   SibSp        418 non-null    int64  \n",
            " 6   Parch        418 non-null    int64  \n",
            " 7   Ticket       418 non-null    object \n",
            " 8   Fare         417 non-null    float64\n",
            " 9   Cabin        91 non-null     object \n",
            " 10  Embarked     418 non-null    object \n",
            "dtypes: float64(2), int64(4), object(5)\n",
            "memory usage: 36.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('test.csv')\n",
        "test_df.drop(\"Name\",axis=1,inplace=True)\n",
        "test_df.drop(\"Ticket\",axis=1,inplace=True)\n",
        "test_df.drop(\"Cabin\",axis=1,inplace=True)\n",
        "test_df.drop(\"Embarked\",axis=1,inplace=True)\n",
        "print(test_df.head())\n",
        "\n",
        "test_df['Sex'].replace(['female', 'male'],[1,0], inplace=True)\n",
        "\n",
        "for i in test_df.columns[1:]: \n",
        "    test_df[i] = test_df[i]/test_df[i].abs().max() \n",
        "\n",
        "test_samples = test_df[[\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\"]].to_numpy()\n"
      ],
      "metadata": {
        "id": "5hs-d58bhnMu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ecaccdf-00ec-4e61-96eb-ecf658214f98"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Pclass     Sex   Age  SibSp  Parch     Fare\n",
            "0          892       3    male  34.5      0      0   7.8292\n",
            "1          893       3  female  47.0      1      0   7.0000\n",
            "2          894       2    male  62.0      0      0   9.6875\n",
            "3          895       3    male  27.0      0      0   8.6625\n",
            "4          896       3  female  22.0      1      1  12.2875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#more on data https://www.kaggle.com/competitions/titanic/data\n",
        "\n",
        "df = pd.read_csv('train.csv') \n",
        "df.drop(\"Name\",axis=1,inplace=True)\n",
        "df.drop(\"Ticket\",axis=1,inplace=True)\n",
        "df.drop(\"Cabin\",axis=1,inplace=True)\n",
        "df.drop(\"Embarked\",axis=1,inplace=True)\n",
        "df = df[['Survived', 'PassengerId', 'Pclass', 'Sex', \"Age\", 'SibSp', 'Parch', 'Fare']]\n",
        "df"
      ],
      "metadata": {
        "id": "HTBvLJSd5RcN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "84a93770-cc10-4ddf-c814-1df5ba65965b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Survived  PassengerId  Pclass     Sex   Age  SibSp  Parch     Fare\n",
              "0           0            1       3    male  22.0      1      0   7.2500\n",
              "1           1            2       1  female  38.0      1      0  71.2833\n",
              "2           1            3       3  female  26.0      0      0   7.9250\n",
              "3           1            4       1  female  35.0      1      0  53.1000\n",
              "4           0            5       3    male  35.0      0      0   8.0500\n",
              "..        ...          ...     ...     ...   ...    ...    ...      ...\n",
              "886         0          887       2    male  27.0      0      0  13.0000\n",
              "887         1          888       1  female  19.0      0      0  30.0000\n",
              "888         0          889       3  female   NaN      1      2  23.4500\n",
              "889         1          890       1    male  26.0      0      0  30.0000\n",
              "890         0          891       3    male  32.0      0      0   7.7500\n",
              "\n",
              "[891 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-94f6be81-2d8b-4291-8afb-3c6a16adcae7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0</td>\n",
              "      <td>887</td>\n",
              "      <td>2</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>0</td>\n",
              "      <td>889</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>23.4500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>0</td>\n",
              "      <td>891</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.7500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94f6be81-2d8b-4291-8afb-3c6a16adcae7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-94f6be81-2d8b-4291-8afb-3c6a16adcae7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-94f6be81-2d8b-4291-8afb-3c6a16adcae7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#drop duplicates, handling missing data https://www.analyticsvidhya.com/blog/2021/05/dealing-with-missing-values-in-python-a-complete-guide/\n",
        "df.isna().sum()\n",
        "df = df.dropna(axis=0)\n",
        "df = df.drop_duplicates()"
      ],
      "metadata": {
        "id": "nE0B_3SH6nL3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#M/F --> 0/1\n",
        "df['Sex'].replace(['female', 'male'],[1,0], inplace=True)\n",
        "#delete outliers > 3 Z-Score\n",
        "df = df[(np.abs(stats.zscore(df)) < 3).all(axis=1)]"
      ],
      "metadata": {
        "id": "WRlLjzAgKSML"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in df.columns[1:]: #skip PassengerId\n",
        "    df[i] = df[i]/df[i].abs().max() #use abs() before max() because loudness has negative values\n",
        "df"
      ],
      "metadata": {
        "id": "TPaQywICL3es",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "ab0b8f3b-2321-4380-a0cc-61743d815d0b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Survived  PassengerId    Pclass  Sex       Age     SibSp  Parch      Fare\n",
              "0           0     0.001122  1.000000  0.0  0.309859  0.333333    0.0  0.043975\n",
              "1           1     0.002245  0.333333  1.0  0.535211  0.333333    0.0  0.432369\n",
              "2           1     0.003367  1.000000  1.0  0.366197  0.000000    0.0  0.048069\n",
              "3           1     0.004489  0.333333  1.0  0.492958  0.333333    0.0  0.322078\n",
              "4           0     0.005612  1.000000  0.0  0.492958  0.000000    0.0  0.048827\n",
              "..        ...          ...       ...  ...       ...       ...    ...       ...\n",
              "884         0     0.993266  1.000000  0.0  0.352113  0.000000    0.0  0.042762\n",
              "886         0     0.995511  0.666667  0.0  0.380282  0.000000    0.0  0.078852\n",
              "887         1     0.996633  0.333333  1.0  0.267606  0.000000    0.0  0.181965\n",
              "889         1     0.998878  0.333333  0.0  0.366197  0.000000    0.0  0.181965\n",
              "890         0     1.000000  1.000000  0.0  0.450704  0.000000    0.0  0.047008\n",
              "\n",
              "[657 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f43bec0-adb0-4c76-8799-54ef3b88cb0f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.001122</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.309859</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.043975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.002245</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.535211</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.432369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.003367</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.366197</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.048069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.004489</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.492958</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.322078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.005612</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.492958</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.048827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>884</th>\n",
              "      <td>0</td>\n",
              "      <td>0.993266</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.352113</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0</td>\n",
              "      <td>0.995511</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.380282</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.078852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>0.996633</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.267606</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.181965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>0.998878</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.366197</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.181965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.450704</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.047008</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>657 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f43bec0-adb0-4c76-8799-54ef3b88cb0f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7f43bec0-adb0-4c76-8799-54ef3b88cb0f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7f43bec0-adb0-4c76-8799-54ef3b88cb0f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\"For linear models (e.g., linear regression or logistic regression), multicolinearity can yield wildly unstable solutions.\"\n",
        "\n",
        "clean_corr = df.corr()#replace 1s with 0s, avoid converting binary audio_mode\n",
        "for i in clean_corr.columns:\n",
        "  clean_corr[i][i] = 0\n",
        "CorrHeat = sn.heatmap(data = clean_corr, cmap='coolwarm', square=True)\n",
        "CorrHeat.set_title(\"Correlation Heatmap\")\n",
        "CorrHeat.xaxis.tick_top()\n",
        "plt.xticks(rotation=90)"
      ],
      "metadata": {
        "id": "3U90dWYPWTZ1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "outputId": "7bd5018f-ec40-46e4-ed6d-3c0d535d75a4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5]),\n",
              " [Text(0.5, 1, 'Survived'),\n",
              "  Text(1.5, 1, 'PassengerId'),\n",
              "  Text(2.5, 1, 'Pclass'),\n",
              "  Text(3.5, 1, 'Sex'),\n",
              "  Text(4.5, 1, 'Age'),\n",
              "  Text(5.5, 1, 'SibSp'),\n",
              "  Text(6.5, 1, 'Parch'),\n",
              "  Text(7.5, 1, 'Fare')])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# age_train_samples = df[[\"Pclass\",\"Sex\",\"SibSp\",\"Parch\",\"Fare\",\"Survived\"]]\n",
        "# age_test_samples = df[[\"Age\"]]\n",
        "\n",
        "# model = Sequential([\n",
        "#     Dense(units = 6, input_shape=(6,), activation = \"relu\", use_bias = True, bias_initializer='zeros'),  # first hidden layer , initialize bias as zeroes\n",
        "#     Dense(units = 6, activation = \"relu\", use_bias=True, bias_initializer=\"zeros\"),                   # second hidden layer, no need for input shape cause knows 4 output in previous\n",
        "#     Dense(units = 1, activation = \"relu\") \n",
        "# ])\n",
        "\n",
        "# model.compile(optimizer = SGD(learning_rate = 0.03), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "# stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "# history = model.fit(x=train_samples, y=train_labels, validation_split=0.1, batch_size = 30, epochs = 100, shuffle = True, verbose = 2, callbacks=[stop_early]) #take 10% to test data\n",
        "# plot_acc(history)\n",
        "\n",
        "# predictions = model.predict(x=test_samples)     # Run our points through our best model\n",
        "# rounded_predictions = np.argmax(predictions, axis = 1)   # Pick the high prob in each prediction \n",
        "\n",
        "# submission = pd.DataFrame()\n",
        "# submission[\"PassengerID\"] = test_df[\"PassengerId\"]\n",
        "# submission[\"Survived\"] = pd.DataFrame(rounded_predictions)\n",
        "# submission.to_csv(\"sean_kickass_submission18.csv\", index = False)"
      ],
      "metadata": {
        "id": "P4v4y8Axh6ym"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples = df[[\"Pclass\",\"Sex\",\"SibSp\",\"Age\",\"Parch\",\"Fare\"]].to_numpy() \n",
        "train_labels = df[[\"Survived\"]].to_numpy()\n",
        "print(train_samples.shape)\n",
        "print(train_labels.shape)\n",
        "#print(train_samples)\n",
        "#print(train_labels)\n",
        "#print(len(train_samples[0]))"
      ],
      "metadata": {
        "id": "kZ6BFIYPyGk_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4a3026f-546a-4d78-d405-7bfb47487782"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(657, 6)\n",
            "(657, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Keras Tuner"
      ],
      "metadata": {
        "id": "vT1AzFmjgXWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_builder(hp): \n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.Input(shape=(6,)))\n",
        "  model.add(keras.layers.Dense(units = hp.Int('layer1', min_value=2, max_value=8, step = 2), activation = \"relu\", use_bias=True, bias_initializer=\"zeros\"))\n",
        "  model.add(keras.layers.Dropout(rate = hp.Float('dropout1', min_value=0.05, max_value=0.25, step = 0.05)))\n",
        "  model.add(keras.layers.Dense(units = hp.Int('layer2', min_value=2, max_value=8, step = 2), activation = \"relu\", use_bias=True, bias_initializer=\"zeros\"))\n",
        "  model.add(keras.layers.Dropout(rate = hp.Float('dropout2', min_value=0.05, max_value=0.25, step = 0.05)))\n",
        "  model.add(keras.layers.Dense(units = 2, activation= \"softmax\"))\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp.Float('learning_rate', min_value=0.01, max_value=0.01, step = 0.01)),\n",
        "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "EPjq78uMgMB9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def bay_builder(hp):\n",
        "#   tuner.search(x=train_samples, y=train_labels, validation_split=0.2, batch_size = 12, epochs = 25, shuffle = False, verbose = 2, callbacks=[stop_early]) "
      ],
      "metadata": {
        "id": "VerjsVw-zR-3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.BayesianOptimization(hypermodel = model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     #max_epochs=20,\n",
        "                     #factor=3,\n",
        "                     #directory='my_dir',\n",
        "                     #project_name='hyper-tuning3'\n",
        "                      overwrite=True,\n",
        "                      max_trials = 20\n",
        "                      )\n",
        "# bay_tuner = kt.BayesianOptimization(hypermodel = bay_builder,\n",
        "#                      objective='val_accuracy',\n",
        "#                      #max_epochs=20,\n",
        "#                      #factor=3,\n",
        "#                      #directory='my_dir',\n",
        "#                      #project_name='hyper-tuning3'\n",
        "#                       overwrite=True\n",
        "#                       )"
      ],
      "metadata": {
        "id": "U0k2aICNgOoW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
      ],
      "metadata": {
        "id": "gJ-rJL0jgQie"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for validation_split in range(10)/30:\n",
        "#   for batch_size in range(5,50,5):\n",
        "#     for epochs in range(10,200,10):\n",
        "tuner.search(x=train_samples, y=train_labels, validation_split=0.2, batch_size = 12, epochs = 25, shuffle = False, verbose = 2, callbacks=[stop_early]) #epochs don't matter here cause we're tuning epochs later anyways. Original is Shuffle = True"
      ],
      "metadata": {
        "id": "-RUtVsyygS9s"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_hp=tuner.get_best_hyperparameters()[0]\n",
        "\n",
        "print(best_hp.values)\n",
        "\n",
        "tuner.results_summary()"
      ],
      "metadata": {
        "id": "0acej4mbgTax",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36fb9be5-ac3a-4101-f0e1-3e72cb3f035d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'layer1': 8, 'dropout1': 0.25, 'layer2': 2, 'dropout2': 0.2, 'learning_rate': 0.01}\n",
            "Results summary\n",
            "Results in ./untitled_project\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_accuracy\", direction=\"max\")\n",
            "\n",
            "Trial 02 summary\n",
            "Hyperparameters:\n",
            "layer1: 8\n",
            "dropout1: 0.25\n",
            "layer2: 2\n",
            "dropout2: 0.2\n",
            "learning_rate: 0.01\n",
            "Score: 0.8636363744735718\n",
            "\n",
            "Trial 12 summary\n",
            "Hyperparameters:\n",
            "layer1: 8\n",
            "dropout1: 0.1\n",
            "layer2: 2\n",
            "dropout2: 0.2\n",
            "learning_rate: 0.01\n",
            "Score: 0.8560606241226196\n",
            "\n",
            "Trial 19 summary\n",
            "Hyperparameters:\n",
            "layer1: 8\n",
            "dropout1: 0.25\n",
            "layer2: 6\n",
            "dropout2: 0.1\n",
            "learning_rate: 0.01\n",
            "Score: 0.8560606241226196\n",
            "\n",
            "Trial 18 summary\n",
            "Hyperparameters:\n",
            "layer1: 8\n",
            "dropout1: 0.1\n",
            "layer2: 6\n",
            "dropout2: 0.15000000000000002\n",
            "learning_rate: 0.01\n",
            "Score: 0.8409090638160706\n",
            "\n",
            "Trial 00 summary\n",
            "Hyperparameters:\n",
            "layer1: 6\n",
            "dropout1: 0.15000000000000002\n",
            "layer2: 8\n",
            "dropout2: 0.25\n",
            "learning_rate: 0.01\n",
            "Score: 0.8333333134651184\n",
            "\n",
            "Trial 16 summary\n",
            "Hyperparameters:\n",
            "layer1: 6\n",
            "dropout1: 0.2\n",
            "layer2: 6\n",
            "dropout2: 0.25\n",
            "learning_rate: 0.01\n",
            "Score: 0.8333333134651184\n",
            "\n",
            "Trial 17 summary\n",
            "Hyperparameters:\n",
            "layer1: 2\n",
            "dropout1: 0.2\n",
            "layer2: 4\n",
            "dropout2: 0.2\n",
            "learning_rate: 0.01\n",
            "Score: 0.8333333134651184\n",
            "\n",
            "Trial 01 summary\n",
            "Hyperparameters:\n",
            "layer1: 4\n",
            "dropout1: 0.2\n",
            "layer2: 8\n",
            "dropout2: 0.05\n",
            "learning_rate: 0.01\n",
            "Score: 0.8257575631141663\n",
            "\n",
            "Trial 03 summary\n",
            "Hyperparameters:\n",
            "layer1: 8\n",
            "dropout1: 0.2\n",
            "layer2: 8\n",
            "dropout2: 0.2\n",
            "learning_rate: 0.01\n",
            "Score: 0.8257575631141663\n",
            "\n",
            "Trial 04 summary\n",
            "Hyperparameters:\n",
            "layer1: 2\n",
            "dropout1: 0.2\n",
            "layer2: 6\n",
            "dropout2: 0.25\n",
            "learning_rate: 0.01\n",
            "Score: 0.8257575631141663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recreating Best Model"
      ],
      "metadata": {
        "id": "cx3RWfspNcRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tuner.hypermodel.build(best_hp) \n",
        "\n",
        "model.summary()\n",
        "history = model.fit(x=train_samples, y=train_labels, validation_split=0.2, batch_size = 12, epochs = 25, shuffle = False, verbose = 2, callbacks=[stop_early])\n",
        "\n",
        "val_acc_per_epoch = history.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ],
      "metadata": {
        "id": "Gn-Job6wJEbR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9d283f5-4b21-4e79-b955-7df7f1f21ac7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 8)                 56        \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 18        \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 2)                 0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 80\n",
            "Trainable params: 80\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "44/44 - 1s - loss: 0.6787 - accuracy: 0.5905 - val_loss: 0.6368 - val_accuracy: 0.6136 - 1s/epoch - 31ms/step\n",
            "Epoch 2/25\n",
            "44/44 - 0s - loss: 0.6176 - accuracy: 0.6362 - val_loss: 0.5534 - val_accuracy: 0.8106 - 142ms/epoch - 3ms/step\n",
            "Epoch 3/25\n",
            "44/44 - 0s - loss: 0.5985 - accuracy: 0.6857 - val_loss: 0.5310 - val_accuracy: 0.8182 - 151ms/epoch - 3ms/step\n",
            "Epoch 4/25\n",
            "44/44 - 0s - loss: 0.5741 - accuracy: 0.7429 - val_loss: 0.5028 - val_accuracy: 0.8258 - 156ms/epoch - 4ms/step\n",
            "Epoch 5/25\n",
            "44/44 - 0s - loss: 0.5541 - accuracy: 0.7638 - val_loss: 0.4938 - val_accuracy: 0.8409 - 149ms/epoch - 3ms/step\n",
            "Epoch 6/25\n",
            "44/44 - 0s - loss: 0.5647 - accuracy: 0.7410 - val_loss: 0.4942 - val_accuracy: 0.8333 - 144ms/epoch - 3ms/step\n",
            "Epoch 7/25\n",
            "44/44 - 0s - loss: 0.5760 - accuracy: 0.7333 - val_loss: 0.4848 - val_accuracy: 0.8409 - 146ms/epoch - 3ms/step\n",
            "Epoch 8/25\n",
            "44/44 - 0s - loss: 0.5344 - accuracy: 0.7676 - val_loss: 0.4554 - val_accuracy: 0.8333 - 154ms/epoch - 4ms/step\n",
            "Epoch 9/25\n",
            "44/44 - 0s - loss: 0.5338 - accuracy: 0.7619 - val_loss: 0.4676 - val_accuracy: 0.8333 - 151ms/epoch - 3ms/step\n",
            "Epoch 10/25\n",
            "44/44 - 0s - loss: 0.5524 - accuracy: 0.7390 - val_loss: 0.4745 - val_accuracy: 0.8333 - 156ms/epoch - 4ms/step\n",
            "Epoch 11/25\n",
            "44/44 - 0s - loss: 0.5456 - accuracy: 0.7486 - val_loss: 0.4698 - val_accuracy: 0.8409 - 151ms/epoch - 3ms/step\n",
            "Best epoch: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrain model with best epoch, submit\n",
        "# hypermodel = model_builder(best_hp)\n",
        "# history = hypermodel.fit(x=train_samples, y=train_labels, validation_split=0.1, batch_size = 30, epochs = best_epoch, shuffle = True, verbose = 2)\n",
        "\n",
        "predictions = model.predict(x=test_samples)     # Run our points through our best model\n",
        "rounded_predictions = np.argmax(predictions, axis = 1)   # Pick the high prob in each prediction \n",
        "print(f\"{predictions=}\")\n",
        "# rounded_predictions = np.rint(predictions) #for binary cross\n",
        "# print(f\"{rounded_predictions=}\") #for binary cross\n",
        "\n",
        "submission = pd.DataFrame()\n",
        "submission[\"PassengerID\"] = test_df[\"PassengerId\"]\n",
        "submission[\"Survived\"] = pd.DataFrame(rounded_predictions)\n",
        "submission.to_csv(\"sean_kickass_submission.csv\", index = False)"
      ],
      "metadata": {
        "id": "ebrt87I4K_E0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd23da3d-35e1-477d-d0e7-01b896f33f84"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 0s 2ms/step\n",
            "predictions=array([[0.6194598 , 0.38054022],\n",
            "       [0.39804372, 0.60195625],\n",
            "       [0.54813963, 0.45186043],\n",
            "       [0.6065794 , 0.3934206 ],\n",
            "       [0.32972753, 0.67027247],\n",
            "       [0.5842265 , 0.41577354],\n",
            "       [0.3274418 , 0.6725582 ],\n",
            "       [0.5358599 , 0.46414015],\n",
            "       [0.30540103, 0.694599  ],\n",
            "       [0.7130883 , 0.28691176],\n",
            "       [       nan,        nan],\n",
            "       [0.41767755, 0.5823225 ],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.5791892 , 0.42081085],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.5022888 , 0.49771115],\n",
            "       [0.59691936, 0.4030806 ],\n",
            "       [0.36072248, 0.63927746],\n",
            "       [0.36116642, 0.6388336 ],\n",
            "       [0.44941708, 0.5505829 ],\n",
            "       [0.55481267, 0.44518736],\n",
            "       [       nan,        nan],\n",
            "       [0.33286515, 0.6671348 ],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.6837515 , 0.31624845],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.5994701 , 0.40052986],\n",
            "       [0.40588903, 0.59411097],\n",
            "       [       nan,        nan],\n",
            "       [0.56766194, 0.43233806],\n",
            "       [0.59807986, 0.4019201 ],\n",
            "       [0.33428675, 0.66571325],\n",
            "       [       nan,        nan],\n",
            "       [0.41447935, 0.5855206 ],\n",
            "       [0.5926551 , 0.4073449 ],\n",
            "       [       nan,        nan],\n",
            "       [0.30927566, 0.6907243 ],\n",
            "       [0.6028996 , 0.39710042],\n",
            "       [       nan,        nan],\n",
            "       [0.6013562 , 0.3986438 ],\n",
            "       [       nan,        nan],\n",
            "       [0.6302318 , 0.36976826],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.6034602 , 0.3965398 ],\n",
            "       [0.41523054, 0.5847695 ],\n",
            "       [       nan,        nan],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.30987346, 0.69012654],\n",
            "       [0.4094503 , 0.5905497 ],\n",
            "       [0.48714462, 0.5128554 ],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [       nan,        nan],\n",
            "       [0.7968501 , 0.20314997],\n",
            "       [0.62026995, 0.37973   ],\n",
            "       [0.603558  , 0.39644197],\n",
            "       [       nan,        nan],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.5898509 , 0.41014907],\n",
            "       [0.49655527, 0.5034447 ],\n",
            "       [0.59161377, 0.40838623],\n",
            "       [0.31145746, 0.6885426 ],\n",
            "       [0.37769148, 0.6223085 ],\n",
            "       [       nan,        nan],\n",
            "       [0.30530584, 0.6946941 ],\n",
            "       [0.41572607, 0.58427393],\n",
            "       [0.38210815, 0.61789185],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.31540206, 0.6845979 ],\n",
            "       [0.59667933, 0.40332067],\n",
            "       [0.32535332, 0.6746467 ],\n",
            "       [0.376333  , 0.623667  ],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.334071  , 0.665929  ],\n",
            "       [       nan,        nan],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.49320418, 0.5067958 ],\n",
            "       [0.31540206, 0.6845979 ],\n",
            "       [0.63736755, 0.36263242],\n",
            "       [0.41956678, 0.58043325],\n",
            "       [0.42260185, 0.5773982 ],\n",
            "       [       nan,        nan],\n",
            "       [       nan,        nan],\n",
            "       [       nan,        nan],\n",
            "       [0.32134753, 0.67865247],\n",
            "       [0.30528083, 0.69471914],\n",
            "       [       nan,        nan],\n",
            "       [0.5106415 , 0.48935848],\n",
            "       [0.3473827 , 0.6526173 ],\n",
            "       [       nan,        nan],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [       nan,        nan],\n",
            "       [0.3704312 , 0.6295688 ],\n",
            "       [0.60350615, 0.39649385],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.6102118 , 0.3897882 ],\n",
            "       [0.30750445, 0.6924956 ],\n",
            "       [0.6168775 , 0.3831225 ],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.54709464, 0.45290536],\n",
            "       [       nan,        nan],\n",
            "       [0.6052052 , 0.39479482],\n",
            "       [0.31741282, 0.6825872 ],\n",
            "       [0.6033435 , 0.39665654],\n",
            "       [0.5967062 , 0.40329376],\n",
            "       [       nan,        nan],\n",
            "       [       nan,        nan],\n",
            "       [0.4728905 , 0.5271095 ],\n",
            "       [0.51189643, 0.4881035 ],\n",
            "       [       nan,        nan],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.3058436 , 0.6941564 ],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.6639403 , 0.33605975],\n",
            "       [       nan,        nan],\n",
            "       [0.29300824, 0.7069918 ],\n",
            "       [0.3814995 , 0.61850053],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [       nan,        nan],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.6087668 , 0.3912332 ],\n",
            "       [       nan,        nan],\n",
            "       [0.29787996, 0.70212007],\n",
            "       [0.59841645, 0.40158352],\n",
            "       [       nan,        nan],\n",
            "       [0.51442397, 0.48557597],\n",
            "       [0.6017214 , 0.39827856],\n",
            "       [0.61520404, 0.38479596],\n",
            "       [0.4289206 , 0.5710794 ],\n",
            "       [       nan,        nan],\n",
            "       [       nan,        nan],\n",
            "       [0.6335072 , 0.36649284],\n",
            "       [0.6017912 , 0.3982088 ],\n",
            "       [0.60624534, 0.39375463],\n",
            "       [0.48613256, 0.51386744],\n",
            "       [0.31335366, 0.68664634],\n",
            "       [0.5480285 , 0.45197147],\n",
            "       [0.36155358, 0.63844645],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.37921202, 0.620788  ],\n",
            "       [0.48483798, 0.51516205],\n",
            "       [0.4094419 , 0.5905582 ],\n",
            "       [0.7637052 , 0.23629482],\n",
            "       [       nan,        nan],\n",
            "       [0.5983256 , 0.4016744 ],\n",
            "       [       nan,        nan],\n",
            "       [0.54278916, 0.45721084],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [       nan,        nan],\n",
            "       [       nan,        nan],\n",
            "       [0.3104835 , 0.6895165 ],\n",
            "       [0.79163647, 0.20836353],\n",
            "       [0.6018996 , 0.39810038],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.31339923, 0.68660074],\n",
            "       [0.4094419 , 0.5905582 ],\n",
            "       [0.30091736, 0.6990826 ],\n",
            "       [       nan,        nan],\n",
            "       [0.63821304, 0.36178702],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [       nan,        nan],\n",
            "       [0.51265657, 0.48734337],\n",
            "       [0.33604458, 0.66395545],\n",
            "       [0.415592  , 0.5844079 ],\n",
            "       [0.69706047, 0.3029395 ],\n",
            "       [       nan,        nan],\n",
            "       [0.31117037, 0.6888296 ],\n",
            "       [       nan,        nan],\n",
            "       [0.6070894 , 0.39291057],\n",
            "       [0.66442156, 0.33557847],\n",
            "       [       nan,        nan],\n",
            "       [0.5782128 , 0.42178723],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.44883847, 0.5511615 ],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.49320418, 0.5067958 ],\n",
            "       [0.40954515, 0.5904549 ],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [       nan,        nan],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.509774  , 0.49022597],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.71945775, 0.28054228],\n",
            "       [       nan,        nan],\n",
            "       [0.5108889 , 0.48911113],\n",
            "       [0.5533746 , 0.44662538],\n",
            "       [       nan,        nan],\n",
            "       [0.6423912 , 0.35760882],\n",
            "       [0.5455168 , 0.4544832 ],\n",
            "       [0.39863497, 0.60136503],\n",
            "       [0.6169463 , 0.38305372],\n",
            "       [0.29248452, 0.7075155 ],\n",
            "       [0.3053211 , 0.6946789 ],\n",
            "       [0.48176053, 0.5182395 ],\n",
            "       [       nan,        nan],\n",
            "       [       nan,        nan],\n",
            "       [0.51593655, 0.48406345],\n",
            "       [0.3839768 , 0.6160232 ],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.485294  , 0.51470596],\n",
            "       [       nan,        nan],\n",
            "       [0.33790728, 0.66209275],\n",
            "       [0.48352703, 0.51647294],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.60347056, 0.3965294 ],\n",
            "       [0.61009586, 0.3899042 ],\n",
            "       [       nan,        nan],\n",
            "       [0.44790807, 0.5520919 ],\n",
            "       [0.31131923, 0.6886808 ],\n",
            "       [0.40199193, 0.59800804],\n",
            "       [0.40503022, 0.5949698 ],\n",
            "       [       nan,        nan],\n",
            "       [0.42009598, 0.5799041 ],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [       nan,        nan],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.5966242 , 0.40337583],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.5967151 , 0.40328488],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [       nan,        nan],\n",
            "       [0.6001155 , 0.39988452],\n",
            "       [       nan,        nan],\n",
            "       [0.6268887 , 0.37311137],\n",
            "       [0.5038158 , 0.49618417],\n",
            "       [0.44578636, 0.55421364],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.6676203 , 0.33237976],\n",
            "       [       nan,        nan],\n",
            "       [0.41706333, 0.5829367 ],\n",
            "       [0.5949906 , 0.40500945],\n",
            "       [0.46102268, 0.5389773 ],\n",
            "       [0.59521604, 0.40478402],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.4078753 , 0.5921247 ],\n",
            "       [       nan,        nan],\n",
            "       [       nan,        nan],\n",
            "       [0.42601806, 0.57398194],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.5515679 , 0.44843203],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [       nan,        nan],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.59496516, 0.4050348 ],\n",
            "       [0.3873153 , 0.61268467],\n",
            "       [0.601267  , 0.39873302],\n",
            "       [0.61553097, 0.38446903],\n",
            "       [       nan,        nan],\n",
            "       [       nan,        nan],\n",
            "       [0.60848343, 0.39151657],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.5967226 , 0.40327746],\n",
            "       [0.6722822 , 0.32771778],\n",
            "       [0.59669423, 0.40330574],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.29365462, 0.7063454 ],\n",
            "       [0.49330175, 0.50669825],\n",
            "       [       nan,        nan],\n",
            "       [       nan,        nan],\n",
            "       [       nan,        nan],\n",
            "       [       nan,        nan],\n",
            "       [0.58957505, 0.41042498],\n",
            "       [0.40580946, 0.59419054],\n",
            "       [       nan,        nan],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [       nan,        nan],\n",
            "       [       nan,        nan],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.49059695, 0.50940305],\n",
            "       [0.558744  , 0.44125602],\n",
            "       [0.55132425, 0.44867578],\n",
            "       [0.47999442, 0.52000564],\n",
            "       [0.31321108, 0.6867889 ],\n",
            "       [0.633682  , 0.36631802],\n",
            "       [       nan,        nan],\n",
            "       [0.30080384, 0.6991962 ],\n",
            "       [0.29338557, 0.70661443],\n",
            "       [0.62216073, 0.37783927],\n",
            "       [       nan,        nan],\n",
            "       [0.40248546, 0.5975145 ],\n",
            "       [       nan,        nan],\n",
            "       [       nan,        nan],\n",
            "       [       nan,        nan],\n",
            "       [0.32760364, 0.67239636],\n",
            "       [       nan,        nan],\n",
            "       [0.43923643, 0.56076354],\n",
            "       [0.62137383, 0.37862614],\n",
            "       [0.60516226, 0.39483777],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [       nan,        nan],\n",
            "       [0.37513888, 0.6248611 ],\n",
            "       [0.6102368 , 0.38976315],\n",
            "       [0.6153009 , 0.3846991 ],\n",
            "       [       nan,        nan],\n",
            "       [0.4883086 , 0.5116914 ],\n",
            "       [0.6015031 , 0.39849687],\n",
            "       [       nan,        nan],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.3586632 , 0.6413368 ],\n",
            "       [0.54397833, 0.4560217 ],\n",
            "       [0.43919381, 0.5608062 ],\n",
            "       [0.39311555, 0.6068844 ],\n",
            "       [0.5912859 , 0.40871415],\n",
            "       [0.5986205 , 0.40137953],\n",
            "       [       nan,        nan],\n",
            "       [0.34247142, 0.65752864],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.30442747, 0.69557256],\n",
            "       [0.42519438, 0.57480556],\n",
            "       [0.4746993 , 0.52530074],\n",
            "       [0.60686624, 0.3931338 ],\n",
            "       [0.59797895, 0.40202108],\n",
            "       [0.6052052 , 0.39479482],\n",
            "       [0.60370773, 0.39629224],\n",
            "       [0.48613256, 0.51386744],\n",
            "       [0.38747033, 0.61252964],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.60038155, 0.39961842],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.40471625, 0.59528375],\n",
            "       [0.54889053, 0.45110947],\n",
            "       [0.47730124, 0.52269876],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.40120563, 0.59879434],\n",
            "       [       nan,        nan],\n",
            "       [0.3220746 , 0.6779254 ],\n",
            "       [0.60685146, 0.39314854],\n",
            "       [0.38039085, 0.6196091 ],\n",
            "       [0.4967412 , 0.5032588 ],\n",
            "       [0.57948434, 0.42051572],\n",
            "       [0.4774977 , 0.5225023 ],\n",
            "       [       nan,        nan],\n",
            "       [0.47293547, 0.52706456],\n",
            "       [0.6153698 , 0.3846302 ],\n",
            "       [       nan,        nan],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [       nan,        nan],\n",
            "       [0.30354133, 0.6964587 ],\n",
            "       [0.48613256, 0.51386744],\n",
            "       [0.34491223, 0.65508777],\n",
            "       [0.482413  , 0.517587  ],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.485294  , 0.51470596],\n",
            "       [0.4496582 , 0.5503418 ],\n",
            "       [0.5382266 , 0.46177337],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.42424673, 0.5757533 ],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [       nan,        nan],\n",
            "       [       nan,        nan],\n",
            "       [0.36556318, 0.63443685],\n",
            "       [0.9048197 , 0.09518029],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.6065794 , 0.3934206 ],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [       nan,        nan],\n",
            "       [       nan,        nan],\n",
            "       [0.30425134, 0.6957486 ],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.49111694, 0.50888306],\n",
            "       [0.5469961 , 0.45300385],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.42884585, 0.5711542 ],\n",
            "       [0.5179576 , 0.48204234],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.36937475, 0.63062525],\n",
            "       [0.47785774, 0.52214223],\n",
            "       [0.4271998 , 0.57280016],\n",
            "       [0.7913593 , 0.2086407 ],\n",
            "       [       nan,        nan],\n",
            "       [0.6051682 , 0.39483184],\n",
            "       [       nan,        nan],\n",
            "       [0.33988065, 0.66011935],\n",
            "       [       nan,        nan],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.6018194 , 0.39818054],\n",
            "       [0.53767157, 0.46232843],\n",
            "       [0.5967315 , 0.40326846],\n",
            "       [0.7565202 , 0.24347979],\n",
            "       [0.34866816, 0.65133184],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.5293039 , 0.47069612],\n",
            "       [0.5229047 , 0.4770953 ],\n",
            "       [0.75705945, 0.24294057],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.6020065 , 0.39799345],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.5984239 , 0.40157607],\n",
            "       [0.6136396 , 0.3863604 ],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.558487  , 0.44151294],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.35494536, 0.64505464],\n",
            "       [0.4374068 , 0.5625932 ],\n",
            "       [0.47521657, 0.52478343],\n",
            "       [0.54827017, 0.45172986],\n",
            "       [0.3934071 , 0.6065929 ],\n",
            "       [       nan,        nan],\n",
            "       [0.29519027, 0.7048097 ],\n",
            "       [       nan,        nan],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.32337728, 0.6766227 ],\n",
            "       [       nan,        nan],\n",
            "       [0.2889601 , 0.71103984],\n",
            "       [0.6263094 , 0.37369058],\n",
            "       [       nan,        nan],\n",
            "       [       nan,        nan]], dtype=float32)\n"
          ]
        }
      ]
    }
  ]
}